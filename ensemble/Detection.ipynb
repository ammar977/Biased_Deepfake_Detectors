{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "523-Proj.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ph6XBtPpqTmb",
        "outputId": "5f0cd564-6b37-4431-cd1d-93fc438003c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQIkoU7GqHDA",
        "outputId": "ecf4e217-989a-4baf-edd9-9c4d223f698f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/523-Project/icpr2020dfdc\n"
          ]
        }
      ],
      "source": [
        "%cd /content/gdrive/MyDrive/523-Project/icpr2020dfdc/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install efficientnet_pytorch  albumentations==0.4.6"
      ],
      "metadata": {
        "id": "8ejQbqomLJAr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.model_zoo import load_url\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import sys\n",
        "sys.path.append('..')\n",
        "\n",
        "from blazeface import FaceExtractor, BlazeFace\n",
        "from architectures import fornet,weights\n",
        "from isplutils import utils"
      ],
      "metadata": {
        "id": "6TUcxKHPxuQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZcVVmxgDgXAU"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Choose an architecture between\n",
        "- EfficientNetB4\n",
        "- EfficientNetB4ST\n",
        "- EfficientNetAutoAttB4\n",
        "- EfficientNetAutoAttB4ST\n",
        "- Xception\n",
        "\"\"\"\n",
        "net_model = 'EfficientNetB4'\n",
        "\n",
        "\"\"\"\n",
        "Choose a training dataset between\n",
        "- DFDC\n",
        "- FFPP\n",
        "\"\"\"\n",
        "train_db = 'DFDC'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mKyKrGeagXAV"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
        "face_policy = 'scale'\n",
        "face_size = 224"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lCEBCwUJgXAX"
      },
      "outputs": [],
      "source": [
        "model_url = weights.weight_url['{:s}_{:s}'.format(net_model,train_db)]\n",
        "net = getattr(fornet,net_model)().eval().to(device)\n",
        "net.load_state_dict(load_url(model_url,map_location=device,check_hash=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dPCykf2egXAY"
      },
      "outputs": [],
      "source": [
        "transf = utils.get_transformer(face_policy, face_size, net.get_normalizer(), train=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9pgHlnVYgXAZ"
      },
      "outputs": [],
      "source": [
        "facedet = BlazeFace().to(device)\n",
        "facedet.load_weights(\"./blazeface/blazeface.pth\")\n",
        "facedet.load_anchors(\"./blazeface/anchors.npy\")\n",
        "face_extractor = FaceExtractor(facedet=facedet)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predictor(im):\n",
        "  im = face_extractor.process_image(img=im)\n",
        "  \n",
        "  if(len(im['faces'])) == 0:\n",
        "    return 0\n",
        "  im = im['faces'][0] # take the face with the highest confidence score found by BlazeFace   \n",
        "\n",
        "  faces_t = torch.stack( [ transf(image=im)['image']] )\n",
        "\n",
        "  with torch.no_grad():\n",
        "    faces_pred = torch.sigmoid(net(faces_t.to(device))).cpu().numpy().flatten()  \n",
        "  return faces_pred[0]"
      ],
      "metadata": {
        "id": "kIxhY4KHN2Ee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DTGLQR3KxHIH"
      },
      "outputs": [],
      "source": [
        "GLOBAL_PATH = '/content/gdrive/MyDrive/523-Project/FakeAVCeleb_v1.2/FakeVideo-RealAudio/'\n",
        "#write_path = '/content/gdrive/MyDrive/523-Project/FakeAVCeleb_v1.2/'\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "with open(GLOBAL_PATH + 'preds.txt' , 'a') as f:\n",
        "  for race in os.listdir(GLOBAL_PATH):\n",
        "    if race == 'preds.txt':\n",
        "      continue\n",
        "    temp1 = GLOBAL_PATH+race+'/'\n",
        "    for gender in os.listdir(temp1):\n",
        "      temp2 = temp1 + gender + '/'\n",
        "      for id in os.listdir(temp2):\n",
        "        temp3 = temp2 + id +'/'\n",
        "        for file in os.listdir(temp3):\n",
        "          if file.endswith('.txt'):\n",
        "            continue\n",
        "          temp4 = temp3 + file\n",
        "          vidcap = cv2.VideoCapture(temp4)\n",
        "          vals = np.zeros(30)\n",
        "          for i in range(0,30):\n",
        "            avg = 0.0\n",
        "            exi,frame = vidcap.read()\n",
        "            if exi == True:\n",
        "              vals[i] = predictor(frame)\n",
        "            else:\n",
        "              break\n",
        "          if i != 0:\n",
        "            f.write(temp4  + '  ' + net_model + '  ' +str(np.mean(vals))  + '   -->  ' + str(1) + '\\n')\n",
        "            f.flush()\n",
        "          else:\n",
        "            continue  \n",
        "\n",
        "\n"
      ]
    }
  ]
}